############################
### 项目运行的环境,dev:开发模式，test:测速模式，production：生产模式
############################
crawler.job.run.mode=dev
############################
### 定制连接实例获取失败报错提示信息
############################
connection.failure.msg = 抱歉！获取的连接的实例失败了哦！！！

############################
###  种子url
############################
#crawler.seed.url=https://www.jd.com/allSort.aspx
crawler.seed.url=https://list.jd.com/list.html?cat=9987,653,655&page=149&sort=sort_rank_asc&trans=1&JL=6_0_0#J_main

############################
###  商品url的前缀
############################
crawler.goods.url.prefix=https://item.jd

############################
###  商品列表url的前缀
############################
crawler.goods.list.url.prefix=https://list.jd

############################
###  京东商城所有品类url的前缀
############################
#crawler.jd.goods.all.url.prefix=https://www.jd.com/allSort.aspx
crawler.jd.goods.all.url.prefix=https://www.jd.com/allSort.aspx

############################
###  接口与其实现类的对应关系
############################
IDowloadBiz=com.l000phone.crawler.download.impl.DownloadBizImpl
IParseBiz=com.l000phone.crawler.parse.impl.JDParseBizImpl
IStoreBiz=com.l000phone.crawler.store.biz.HBaseStoreBizImpl
#IStoreBiz=com.l000phone.crawler.store.biz.RDBMSStoreBizImpl
#IStoreBiz=com.l000phone.crawler.store.biz.HBaseStoreBizImpl
#单机版的单个电商平台的爬虫
#IUrlPrepositoryBiz = com.l000phone.crawler.repository.impl.UrlQueuePrepositoryBizImpl
#分布式单个电商平台的爬虫
#IUrlPrepositoryBiz =com.l000phone.crawler.repository.impl.UrlRedisPrepositoryImpl
#单机版的全网爬虫
#IUrlPrepositoryBiz =com.l000phone.crawler.repository.impl.RandomPrepositoryAllBizImpl
#分布式版的全网爬虫
IUrlPrepositoryBiz =com.l000phone.crawler.repository.impl.RandomRedisPrepositoryAllBizImpl
############################
###  Redis内存数据库三个key
############################
crawler.url.redis.repository.higher.key=higer-level 
crawler.url.redis.repository.lower.key=lower-level
crawler.url.redis.repository.other.key=other-level
crawler.url.redis.repository.common.key=common-url
############################
###  Common url 清空flg(0~> 分布式爬虫中第一个，清空,1~>分布式爬虫中后续的爬虫，不用处理)
############################
crawler.url.clear.first.flg=0
crawler.url.clear.other.flg=1 

############################
###  运维人员定时向redis中添加种子url对应的key
############################
crawler.admin.new.add.seed.key=new-add-seed-url